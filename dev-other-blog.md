" Set text width as 72.

### My blog for stuff that i used to post on twitter

... so no i am putting my observations over here, instead of posting them on social media (kind of)


<!--
---14/06/23 04:16:45----------------------

I had an interesting conversation with Google Bard, the poor robot is getting lost quickly, or rather not? Interesting that they now improving the quality of handling logic reasoning tasks by adding "implicit code execution"  [link](https://atlasalpha.serenebase.com/post?recordId=recZF8XUdJxXWleF6). I keep wandering to what extent this technique can be generalized, but that is probably a kind of philosophical question...

> how does google monetize personal data obtained by google bard?

Google monetizes personal data obtained from the logs of a user's conversation with Google Bard in a number of ways. These include:

    Targeted advertising: Google uses the data to target users with ads that are more likely to be relevant to their interests. For example, if a user talks to Google Bard about their favorite TV show, Google might show them ads for merchandise related to that show.
    Product development: Google uses the data to improve its products and services. For example, if a user talks to Google Bard about a problem they're having with their phone, Google might use that information to develop a new feature that will help other users with the same problem.
    Research: Google uses the data for research purposes. For example, Google might use the data to study how people use its products and services, or to develop new technologies.

Google has a number of privacy policies in place that govern how it collects and uses personal data. These policies are designed to protect users' privacy and to give users control over their data. For example, users can opt out of targeted advertising, and they can delete their personal data from Google's servers.

It is important to note that Google is not the only company that monetizes personal data. Many other companies, including social media companies, also collect and use personal data to target users with ads, develop products and services, and conduct research.

Users can protect their privacy by being aware of how their data is being collected and used, and by taking steps to limit the amount of data they share. For example, users can use privacy settings to control how their data is shared, and they can use ad blockers to prevent companies from tracking them across the web.

Here are some additional tips for protecting your privacy when using Google Bard:

    Use a private browsing mode when you're talking to Google Bard. This will prevent Google from tracking your activity across different websites.
    Don't share any personal information that you don't want Google to have. This includes your name, address, phone number, and email address.
    Be careful about what you say to Google Bard. Google may use what you say to improve its products and services, or to conduct research.

By following these tips, you can help protect your privacy when using Google Bard.

> doesn't that contradict the GDPR?

Yes, it is possible that Google's monetization of personal data obtained from the logs of a user's conversation with Google Bard could contradict the GDPR. The GDPR is a European Union regulation that gives individuals more control over their personal data. It requires companies to obtain consent from individuals before collecting or using their personal data, and it gives individuals the right to access, correct, or delete their personal data.

Google has argued that its monetization of personal data does not contradict the GDPR because it obtains consent from individuals before collecting or using their data. However, some privacy advocates have argued that Google's consent mechanism is not valid because it is not clear and specific. They have also argued that Google's use of personal data for targeted advertising and research purposes does not fall within the scope of the consent that individuals have given.

It is possible that the European Data Protection Board (EDPB), which is the EU's independent supervisory authority for data protection, will investigate Google's monetization of personal data and make a ruling on whether it is in compliance with the GDPR. If the EDPB finds that Google's practices are not in compliance with the GDPR, it could order Google to stop collecting or using personal data in this way.

In the meantime, individuals who are concerned about their privacy when using Google Bard can take steps to protect their data, such as using a private browsing mode and not sharing any personal information that they do not want Google to have.

> There is a problem with your last bit of advise: Google bard requires to log in with a google account, when accessed via a browser window in private browsing mode

... Poor robot is getting lost here...

> But the google bard faq is stating that google is not using my Bard conversations for advertising purposes. See https://bard.google.com/faq

I apologize for the confusion. You are correct, Google is not using your Bard conversations for advertising purposes. The Google Bard FAQ that you linked to states the following:

    Do you use my Bard conversations for advertising purposes?

    Bard conversations are not being used for advertising purposes, and we will clearly communicate any changes to this approach in the future. Read our Privacy and Security Principles to better understand how we keep our users' data private, safe, and secure. Visit your Google Account to access settings and tools that let you safeguard your data and protect your privacy.

I understand that you may still have some concerns about your privacy when using Google Bard. I want to assure you that Google takes your privacy very seriously. Google's Privacy and Security Principles outline the company's commitment to protecting user data. These principles include the following:

    Transparency: Google is committed to being transparent about how it collects, uses, and shares user data.
    Choice: Google gives users control over their data. Users can choose whether or not to share their data with Google, and they can choose how their data is used.
    Security: Google takes security very seriously. Google uses a variety of security measures to protect user data, including encryption, access controls, and audits.

If you have any further questions about Google's privacy practices, please visit the Google Privacy & Security website.
//-->

---14/06/23 03:43:55----------------------

It just dawned on my that Jupyter Notebook is supposed to be a form of literate programming, where documentation is a first-class citizen.

However Knuth thought more in terms of macros, as a kind of section that is being expanded upon, and Jupyter Notebook doesn't do these.

See more on wikipedia [here](https://en.wikipedia.org/wiki/Literate_programming)

---31/05/23 05:51:00----------------------

Found an area where ChatGTP/Google Bard can be used with great benefit:  I am not an expert in frontend stuff, but now I had to fiddle with CSS style sheets - the LLM knows all the style combinations, and its recommendations worked!

They might have done some specialized training on CSS, I had less success when asking about other API's.


---24/05/23 05:04:20----------------------

1816 was a year without summer, this video says that this event was related to the invention of the [Draisine](https://en.wikipedia.org/wiki/Draisine) - that's an early form of the bicycle 

Oats were seven times more expensive, due to a bad harvest that came with the year without summer. Horses are eating oats, therefore ownership of a horse became a problem. 
Therefore people were looking for other forms of transportation, in other words they were looking for a substitute for the horse.

See this [video (in Russian)](https://www.youtube.com/watch?v=mcfm8IFhyz0&t=700s)

Also the invention oft the steam engine had something to do with relatively high salaries in Britain, whereas energy was a cheap thing. They industrial revolution just didn't catch on in the rest of Europe quite as early as in England (later Britain), due to a lack of these factors - they could still manage with manual labor, because it was cheap enough...

See [link](https://www.nuffield.ox.ac.uk/users/Allen/unpublished/econinvent-3.pdf)


---23/05/23 06:40:48----------------------

Saw a wonderful movie "Those Magnificent men in their flying machines". 

> Captain Rumpelstoss : But... how will I learn to fly?
> 
> Count Manfred Von Holstein : Same way as we learn everything else in the German army: From the book of instructions!

I am hardly watching modern movies, somehow got the impression they now have a problem with their script, the script nowadays often looks incomplete with a fragmented narrative (maybe it's just my impression).

Let's ask "Dr. Know" aka Google Bard:

> > Movie scripts in contemporary movies often look incoherent, incomplete with a fragmented narrative. Is that a correct impression?
>
> It is true that some contemporary movies have incoherent, incomplete, and fragmented narratives. This is due to a number of factors, including the rise of streaming services, the increasing popularity of independent films, and the changing tastes of audiences.
>
> Streaming services have made it easier for filmmakers to produce and distribute their films, regardless of their budget or genre. This has led to a proliferation of films, many of which are not well-made or well-written. As a result, audiences are more likely to be exposed to films with incoherent or incomplete narratives.
>
> Independent films have also become more popular in recent years. These films are often made with smaller budgets and less studio interference, which can lead to more creative and experimental storytelling. However, this can also lead to films that are difficult to follow or understand.
>
> Finally, the tastes of audiences have changed in recent years. Audiences are now more interested in films that are visually stunning and emotionally engaging, even if they do not have a traditional narrative structure. This has led to a trend of films with fragmented narratives, which are often more visually appealing and emotionally resonant than traditional films.
>
> It is important to note that not all contemporary movies have incoherent, incomplete, or fragmented narratives. There are still many well-made films with traditional narrative structures being produced today. However, the rise of streaming services, the increasing popularity of independent films, and the changing tastes of audiences have all contributed to the trend of films with more fragmented narratives.

I am not quite sure if writers still know how to write a coherent script - people are getting used to stuff that doesn't make sense, I think it's a tragedy...

--

Saw some Christopher Nolan movies, i think he wants to be post-modern. Now in post-modernism they don't do linear storytelling out of principle (i think that this makes for movies that are harder to understands, the 'usability' of such a movie is suffering significantly); again asked google bard for the reasoning behind all this:

> > why does post modernism dislike linear storytelling?
>
> Postmodernism is a philosophical movement that began in the mid-20th century and has had a significant impact on many areas of culture, including literature, art, and architecture. One of the key features of postmodernism is its rejection of traditional forms of storytelling, such as linear narratives.
> 
> There are a number of reasons why postmodernists dislike linear storytelling. First, they see it as a form of oppression. Linear narratives typically present a single, unified perspective on the world, which can be seen as a way of suppressing alternative viewpoints. Second, postmodernists believe that linear narratives are unrealistic. The world is not a neatly ordered place, and stories that attempt to present it as such are often seen as false or misleading. Finally, postmodernists believe that linear narratives are boring. They argue that stories that follow a predictable path are not as engaging as those that are more complex and unpredictable.
> 
> Instead of linear narratives, postmodernists often prefer to use fragmented, nonlinear forms of storytelling. These forms of storytelling can be more challenging for readers, but they can also be more rewarding. They allow readers to participate in the creation of meaning, and they can help readers to see the world in new and different ways.
>
> > I think that movies that adopt non linear storytelling are hard to watch
> 
> I can understand why you might find non-linear movies hard to watch. They can be confusing and disorienting, and they can make it difficult to follow the story. However, there are also many benefits to non-linear storytelling.
> 
> For one, it can be a more realistic way of telling a story. The world is not always neatly ordered, and stories that attempt to present it as such can often feel false or misleading. Non-linear stories can help to capture the complexity and messiness of real life.
> 
> Additionally, non-linear stories can be more engaging and suspenseful. When the audience is not sure what is going to happen next, they are more likely to stay engaged in the story. Non-linear stories can also be more emotionally powerful, as they can allow the audience to experience the story from different perspectives.
> 
> Of course, non-linear storytelling is not for everyone. Some people simply prefer the comfort of a linear narrative. However, if you are willing to give it a chance, you may be surprised at how rewarding non-linear storytelling can be.

It's funny, but these language models are heavily influenced by the way the question has been asked. The way of how you ask it a question makes for half of the answer...

The funny thing is that any answer returned by an LLM has this polished air of authority. I think the worst think that can happen is to take this answer as-is and to stop asking further questions. Just look at the question from a slightly different angle - and you will get a totally different answer...

(also all this non-linear storytelling comes from critical theory and postmodernism (Gasp), i think postmodernism is crap [see wikipedia](https://en.wikipedia.org/wiki/Criticism_of_postmodernism) )

>
>Linguist Noam Chomsky has argued that postmodernism is meaningless because it adds nothing to analytical or empirical knowledge. He asks why postmodernist intellectuals won't respond like people in other fields when asked:
>
>    Seriously, what are the principles of their theories, on what evidence are they based, what do they explain that wasn't already obvious, etc? These are fair requests for anyone to make. If they can't be met, then I'd suggest recourse to Hume's advice in similar circumstances: to the flames.[6]
>


---17/05/23 03:04:37----------------------

[This article](https://arxiv.org/abs/2205.11916) - adding "Let's think step by step" to a prompt will result in a more focused answer from ChatGTP that is less likely to go with hallucinations.

Now [Denny Zhou](https://twitter.com/denny_zhou/status/1529294079195897856) tells us that some of the ChatGTP models have been "finetuned with 'let's think step by step.'"

Such a finetuning stage means, that they added a supervised learning stage with pre-selected dialogues that are written as a series of steps (says Google Bard) 

At least that's a rational sounding explanation: I suspect that this is not the only trick in prompt engineering which has a rational explanation...

Asking Google Bard (it seems that only an LLM is able to explain things about this field clearly, without recourse to jargon and without recursive acronyms...)

(Also my trick: ask the robot about his sources for information in the form 'can you provide a link to the articles that are the source of this information?' )


Now this fine-tuning seems to be turning into a big business. Let's learn about it, first asking google bard (that's the LLM with the latest knowledge cutoff date - so it should know about recent stuff)

> >How are LLM models fine tuned?
>
> Fine-tuning is the process of adjusting the parameters of a pre-trained large language model (LLM) to improve its performance on a specific task or domain. This is done by training the LLM on a smaller dataset that is specific to the task or domain. The fine-tuning process typically involves:
> 
> Data preparation: The first step is to prepare the data for fine-tuning. This involves cleaning the data, removing any errors or inconsistencies, and formatting it in a way that is compatible with the LLM.
> Model selection: The next step is to select a model to fine-tune. There are a number of different LLMs available, each with its own strengths and weaknesses. The best model for a particular task will depend on a number of factors, such as the size of the dataset, the complexity of the task, and the desired performance.
> Training: The final step is to train the LLM on the fine-tuning dataset. This is typically done using a supervised learning approach, where the LLM is trained to predict the correct output for a given input. The training process can be time-consuming, as it involves iteratively adjusting the model's parameters to minimize the error rate.
>
> Once the LLM has been fine-tuned, it can be used to perform the desired task. The fine-tuned model will typically be more accurate and efficient than the pre-trained model.
> Here are some additional details about each step of the fine-tuning process:
>
> Data preparation: The data preparation step is important to ensure that the LLM is trained on high-quality data. The data should be cleaned to remove any errors or inconsistencies. It should also be formatted in a way that is compatible with the LLM. For example, if the LLM is a text-based model, the data should be in the form of text files.
>
> Model selection: There are a number of different LLMs available, each with its own strengths and weaknesses. The best model for a particular task will depend on a number of factors, such as the size of the dataset, the complexity of the task, and the desired performance. For example, if the task is to generate text, a model with a large vocabulary and a good understanding of grammar will be required.
>
> Training: The training process is typically done using a supervised learning approach, where the LLM is trained to predict the correct output for a given input. The training process can be time-consuming, as it involves iteratively adjusting the model's parameters to minimize the error rate. The amount of time required for training will depend on a number of factors, such as the size of the dataset, the complexity of the task, and the desired performance.
>
> Fine-tuning is a powerful technique that can be used to improve the performance of LLMs on a variety of tasks. By carefully selecting a model and training it on a high-quality dataset, it is possible to achieve significant improvements in performance.
>
> >can you provide a link to the articles that are the source of this information?
>
> Sure. Here are some links to the articles that I used as sources for my information about fine-tuning large language models:
>
>  Research papers:
>      "Fine-Tuning Language Models for Natural Language Processing Tasks" by Howard and Ruder (2018)
>            "Parameter-Efficient Fine-Tuning of Large-Scale Pre-Trained Language Models" by Radford et al. (2020)
>           "Scaling Laws for Neural Language Models" by Brown et al. (2020)
>
>        Blog posts:
>            "Fine-Tuning Large Language Models" by Sebastian Raschka (2022)
>            "Fine-Tuning a Large Language Model with Python" by Marcello Politi (2023)
>            "How to Fine-Tune a Large Language Model" by Cobus Greyling (2023)
>
>        Online tutorials:
>            "Fine-Tuning BERT for Text Classification" by Hugging Face (2020)
>            "Fine-Tuning DistilBERT for Text Classification" by Hugging Face (2021)
>            "Fine-Tuning RoBERTa for Text Classification" by Hugging Face (2022)
>
>    I hope this helps!


---12/05/23 18:37:40----------------------

I tried to make a page, where chatgtp and google bard appear side-by-side on the same page, each of them embedded in an iframe tag. (tried to send the same prompt to both of them, in order to display both results side-by-side).

Now google bard doesn't allow that! They are sending the ```Cross-Origin-Resource-Policy``` http header with value ```same-origin``` - therefore it's impossible to embed them in an iframe that comes from a domain other than *.google.com.

The reason is that the javascript on the embedding page can access the DOM of the embedded page (google bard in this case) - and that opens the room for cross-site attacks.

Now this feature probably disables some of the queries on my [duckduckbang!](https://github.com/MoserMichael/duckduckbang) project. Nasty...


---09/05/23 05:10:30----------------------

Is LLM [prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering) is the art of asking a questions to the language model, one that is likely to produce a better result. 
The idea looks similar to  ... [Robopsychology](https://en.wikipedia.org/wiki/Robopsychology) in 'I Robot' by Asimov

We are living in an interesting time...

A different view would be, that it's just a way to optimize the results of a search engine.

Now this following [paper](https://arxiv.org/pdf/2212.04037.pdf) argues, that the simplest LLM prompts work best, probably the prompt that has a style and wording nearest to the text of training data has the best chances.

"from the article: "we devise the following straightforward procedure:

1. Obtain a small set of manually created prompts for the task.

2. Expand the set of prompts with automatic paraphrasing using a LM (e.g., GPT3) and backtranslation (see Section 3).

3. Rank the list of prompts by perplexity (aver- aged on a representative sample of task inputs, e.g. 1,000).

4. Choose the k (e.g., 3) lowest perplexity prompts.

Using this algorithm, we show empirically that it is best to prioritize experimenting with the lowest perplexity prompts, as they perform better than manual prompts on average, and are more stable" 


How is the automatic paraphrasing achieved?

* first they paraphrase the hand written prompts: "We prompt it with a meta-prompt for paraphrasing to generate variations of one of our seed prompts. An example of such a meta-prompt is: Write a paraphrase for the following sentence: <seed prompt> Paraphrase:.  The 7 meta-prompts used in this step are listed in Section A in the Appendix.  We choose GPT3 as our paraphrasing model because of its well-documented generation abilities.  This is also to ensure that there is a separation between the model we use to create the prompts and the models we use to rank them (OPT and Bloom, see Section 4 for details)"
* then they translate the text from the previous step to a different language and back into english. (the article doesn't quite explain the reasoning behind this step)


Still there is this interesting practice of 'prompt engineering. https://github.com/brexhq/prompt-engineering#a-brief-incomplete-and-somewhat-incorrect-history-of-language-models



---08/05/23 09:02:53----------------------

Just realized: ChatGTP isn't hallucinating, these are Androids who are dreaming of electric sheep!

Now I am re-reading "Do Androids dream of electric sheep" by Philip K Dick, so writing down the memorable phrases/scenes. [more...](androids-electric-sheep.txt)

/actually pasting out memorable phrases is a nice trick - for staying focused on the text, while you have half a hundred tab windows open in the web browser...
The good part is that this method can help with last point in the text (it's like a bookmark) - just search for the last phrase that got copied in the notes/

... And the Androids in the book also do have hallucinations! "Maybe that's a false memory. Don't androids sometimes go around with false memories?"

---08/05/23 05:56:47----------------------

[Stack Overflow is ChatGPT Casualty: Traffic Down 14% in March](https://www.similarweb.com/blog/insights/ai-news/stack-overflow-chatgpt/)

So where the stack overflow posts ... training their own replacement?
But if any harm comes to SO then the quality of the tech answers in ChatGTP will also be affected.

As Berthold Brecht said "So many reports. So many questions."  [Questions of a reading worker](https://www.emag-augsburg.de/2018/02/21/questions-of-a-reading-worker/)

Submitted the link to HN [discussion on HN](https://news.ycombinator.com/item?id=35857536)

---07/05/23 06:17:15----------------------

I have summed up an interesting interview with Erica Franz on Authoritarian regimes [link to my summary](political-stuff.txt) - with specific reference to Putins attempts to resurrect Stalinism.

In Soviet school they used to teach us that Lenin was writing summaries of the stuff that he read [here](https://prorivists.org/how_lenin_worked_with_a_book/) - so they forced us to do likewise... Somehow i have come to think that this is a good practice (of course Lenin's regime was a very nasty one...)


Interesting that Socrates didn't like to write things down ... among other reasons because it 'destroys memory and weakens the mind'.
[see here](https://blogs.ubc.ca/etec540sept13/2013/09/29/socrates-writing-vs-memory/) 

Interesting that Socrates is reported to have told the story two Egyptian deities Theuth and Thamus. These ancient greeks must have travelled a lot: see [here](https://history.howstuffworks.com/history-vs-myth/greek-philosophers-african-tribes1.htm) 

"It's well-documented that classical Greek thinkers traveled to what we now call Egypt to expand their knowledge. When the Greek scholars Thales, Hippocrates, Pythagoras, Socrates, Plato and others traveled to Kemet, they studied at the temple-universities Waset and Ipet Isut"

---07/05/23 16:01:46----------------------

Have come across Mr. [Avva](https://avva.livejournal.com). I got the impression that he is kind of asking directly for my feedback - however it turns out, that he is quietly removing all of my comments to his 'blog'.

- somehow it touched me, that even the owner of a nasty little blog is playing politics (apparently they all do that)
- the owner of big platforms are always in control of who is seeing the scribble (if you pay Elon Musk then he is more likely to show your comment - the blue tick gives 'Prioritized rankings in conversations and search' see https://help.twitter.com/en/using-twitter/twitter-blue )
- also it somehow dawned on me, that these platforms have some agenda of their own (they aren't here for the sake of free speech) - they are just playing their politics 'by other means'.
- any feedback is a way to feed these corporate trolls - attention is their currency. Also my dear late Mother told me not to take part in any of these useless parlors... (in the end those who are in charge will choose to ignore my feedback - to their own liking)

What's left? Open source - that's a different kind of medium (they can't censor me here, but they can ignore me)

Why is speech allowed around here?

- they sort of agreed not to own the content of any public repository, however things are slightly different on social media:  (I was shocked to read that '... Facebook's terms allow them "a non-exclusive, transferable, sub-licensable, royalty-free, worldwide license to use any IP content that you post on or in connection with Facebook." In layman's terms, Facebook has license to use the photos and videos you post (which you own) in any way it sees fit, without paying you, and it can transfer that license to third parties.' https://www.findlaw.com/legalblogs/law-and-life/who-legally-owns-your-facebook-posts/ ) 
- Because they are in a sense depending on the output created by the open source movement (see [We have no moat](https://www.semianalysis.com/p/google-we-have-no-moat-and-neither) ), therefore they can't censor that medium (if you care to listen then there is some similarity here to the Prophets of the Hebrew Bible - just in a more modern sense)

Social networks: should i stay or should i go?

- Maybe that's the point of leaving all these social networks and all of these 'discussion forums'; a real person with any senses won't take part in this show:
- any reasonable person is aware of the fact that the impact of the message is controlled by the owner of the platform
- any reasonable person is aware of the fact that his speech will be held against him, that may happen - whenever the weather turns bad.

... but now i see that it doesn't serve me any purpose, and my attention is their currency - so I am literally feeding the trolls, as they are all trolling for attention.
So now i know for sure that there is [no point](https://www.youtube.com/watch?v=264BO4SKXn4) in taking part in any of these online discussions.

A clever person is there for the news, not in order to provide any unwarranted feedback (you won't be able to change anything in any way)

(i guess this repo will still hold my thoughts, protected by the fact that those in charge will not care about my scribble)

(now let's see i i can follow all this through. So far i have always crawled back to online forum participation - upon the slightest provocation, but then i was scribbling more on Facebook and twitter due to the pandemic, but the pandemic is kind of ... over)

Therefore welcome to the ... new blog for [stuff that i used to post on twitter](dev-other-blog.md)

---04/05/23 06:34:50----------------------

me talking with ChatGTP on classical AI and the attempts to combine classical AI with ML
[link to the talk](talking-with-chatgtp.md)

I have come to think that ChatGTP is very good at this kind of general discussions.

(also I appreciate the lack of hubris on the part of ChatGTP - very unlike all the real workers in the field. ChatGTP is also always there to explain these frequent acronyms and explains what it is referring to - you just have to ask...)

/later discovered that Google Bard is better at it - because it has a later knowledge cutoff date than ChatGTP3.5 ; this means that the data used to train Google Bard is newer and more up to date than that of ChatGTP3.5/



