" Set text width as 72.

### My blog for stuff that i used to post on twitter

... so no i am putting my observations over here, instead of posting them on social media (kind of)


---24/05/23 05:04:20----------------------

1816 was a year without summer, this video says that this event was related to the invention of the [Draisine](https://en.wikipedia.org/wiki/Draisine) - that's an early form of the bicycle 

Oats were seven times more expensive, due to a bad harvest that came with the year without summer. Horses are eating oats, therefore ownership of a horse became a problem. 
Therefore people were looking for other forms of transportation, in other words they were looking for a substitute for the horse.

See this [video (in Russian)](https://www.youtube.com/watch?v=mcfm8IFhyz0&t=700s)

Also the invention oft the steam engine had something to do with relatively high salaries in Britain, whereas energy was a cheap thing. They industrial revolution just didn't catch on in the rest of Europe quite as early as in England (later Britain), due to a lack of these factors - they could still manage with manual labor, because it was cheap enough...

See [link](https://www.nuffield.ox.ac.uk/users/Allen/unpublished/econinvent-3.pdf)


---23/05/23 06:40:48----------------------

Saw a wonderful movie "Those Magnificent men in their flying machines". 

    Captain Rumpelstoss : But... how will I learn to fly?

    Count Manfred Von Holstein : Same way as we learn everything else in the German army: From the book of instructions!

I am hardly watching modern movies, somehow got the impression they now have a problem with their script, the script nowadays often looks incomplete with a fragmented narrative (maybe it's just my impression).

    > Movie scripts in contemporary movies often look incoherent, incomplete with a fragmented narrative. Is that a correct impression?

    It is true that some contemporary movies have incoherent, incomplete, and fragmented narratives. This is due to a number of factors, including the rise of streaming services, the increasing popularity of independent films, and the changing tastes of audiences.

    Streaming services have made it easier for filmmakers to produce and distribute their films, regardless of their budget or genre. This has led to a proliferation of films, many of which are not well-made or well-written. As a result, audiences are more likely to be exposed to films with incoherent or incomplete narratives.

    Independent films have also become more popular in recent years. These films are often made with smaller budgets and less studio interference, which can lead to more creative and experimental storytelling. However, this can also lead to films that are difficult to follow or understand.

    Finally, the tastes of audiences have changed in recent years. Audiences are now more interested in films that are visually stunning and emotionally engaging, even if they do not have a traditional narrative structure. This has led to a trend of films with fragmented narratives, which are often more visually appealing and emotionally resonant than traditional films.

    It is important to note that not all contemporary movies have incoherent, incomplete, or fragmented narratives. There are still many well-made films with traditional narrative structures being produced today. However, the rise of streaming services, the increasing popularity of independent films, and the changing tastes of audiences have all contributed to the trend of films with more fragmented narratives.


I am not quite sure that writers still know how to write a coherent script - people are getting used to stuff that doesn't make sense, I think it's a tragedy...

---17/05/23 03:04:37----------------------

[This article](https://arxiv.org/abs/2205.11916) - adding "Let's think step by step" to a prompt will result in a more focused answer from ChatGTP that is less likely to go with hallucinations.

Now [Denny Zhou](https://twitter.com/denny_zhou/status/1529294079195897856) tells us that some of the ChatGTP models have been "finetuned with 'let's think step by step.'"

Such a finetuning stage means, that they added a supervised learning stage with pre-selected dialogues that are written as a series of steps (says Google Bard) 

At least that's a rational sounding explanation: I suspect that this is not the only trick in prompt engineering which has a rational explanation...

Asking Google Bard (it seems that only an LLM is able to explain things about this field clearly, without recourse to jargon and without recursive acronyms...)

(Also my trick: ask the robot about his sources for information in the form 'can you provide a link to the articles that are the source of this information?' )


Now this fine-tuning seems to be turning into a big business. Let's learn about it, first asking google bard (that's the LLM with the latest knowledge cutoff date - so it should know about recent stuff)

    >How are LLM models fine tuned?

    Fine-tuning is the process of adjusting the parameters of a pre-trained large language model (LLM) to improve its performance on a specific task or domain. This is done by training the LLM on a smaller dataset that is specific to the task or domain. The fine-tuning process typically involves:

    Data preparation: The first step is to prepare the data for fine-tuning. This involves cleaning the data, removing any errors or inconsistencies, and formatting it in a way that is compatible with the LLM.
    Model selection: The next step is to select a model to fine-tune. There are a number of different LLMs available, each with its own strengths and weaknesses. The best model for a particular task will depend on a number of factors, such as the size of the dataset, the complexity of the task, and the desired performance.
    Training: The final step is to train the LLM on the fine-tuning dataset. This is typically done using a supervised learning approach, where the LLM is trained to predict the correct output for a given input. The training process can be time-consuming, as it involves iteratively adjusting the model's parameters to minimize the error rate.

    Once the LLM has been fine-tuned, it can be used to perform the desired task. The fine-tuned model will typically be more accurate and efficient than the pre-trained model.

    Here are some additional details about each step of the fine-tuning process:

    Data preparation: The data preparation step is important to ensure that the LLM is trained on high-quality data. The data should be cleaned to remove any errors or inconsistencies. It should also be formatted in a way that is compatible with the LLM. For example, if the LLM is a text-based model, the data should be in the form of text files.

    Model selection: There are a number of different LLMs available, each with its own strengths and weaknesses. The best model for a particular task will depend on a number of factors, such as the size of the dataset, the complexity of the task, and the desired performance. For example, if the task is to generate text, a model with a large vocabulary and a good understanding of grammar will be required.

    Training: The training process is typically done using a supervised learning approach, where the LLM is trained to predict the correct output for a given input. The training process can be time-consuming, as it involves iteratively adjusting the model's parameters to minimize the error rate. The amount of time required for training will depend on a number of factors, such as the size of the dataset, the complexity of the task, and the desired performance.

    Fine-tuning is a powerful technique that can be used to improve the performance of LLMs on a variety of tasks. By carefully selecting a model and training it on a high-quality dataset, it is possible to achieve significant improvements in performance.


    >can you provide a link to the articles that are the source of this information?


    Sure. Here are some links to the articles that I used as sources for my information about fine-tuning large language models:

        Research papers:
            "Fine-Tuning Language Models for Natural Language Processing Tasks" by Howard and Ruder (2018)
            "Parameter-Efficient Fine-Tuning of Large-Scale Pre-Trained Language Models" by Radford et al. (2020)
            "Scaling Laws for Neural Language Models" by Brown et al. (2020)

        Blog posts:
            "Fine-Tuning Large Language Models" by Sebastian Raschka (2022)
            "Fine-Tuning a Large Language Model with Python" by Marcello Politi (2023)
            "How to Fine-Tune a Large Language Model" by Cobus Greyling (2023)

        Online tutorials:
            "Fine-Tuning BERT for Text Classification" by Hugging Face (2020)
            "Fine-Tuning DistilBERT for Text Classification" by Hugging Face (2021)
            "Fine-Tuning RoBERTa for Text Classification" by Hugging Face (2022)

    I hope this helps!


---12/05/23 18:37:40----------------------

I tried to make a page, where chatgtp and google bard appear side-by-side on the same page, each of them embedded in an iframe tag. (tried to send the same prompt to both of them, in order to display both results side-by-side).

Now google bard doesn't allow that! They are sending the ```Cross-Origin-Resource-Policy``` http header with value ```same-origin``` - therefore it's impossible to embed them in an iframe that comes from a domain other than *.google.com.

The reason is that the javascript on the embedding page can access the DOM of the embedded page (google bard in this case) - and that opens the room for cross-site attacks.

Now this feature probably disables some of the queries on my [duckduckbang!](https://github.com/MoserMichael/duckduckbang) project. Nasty...


---09/05/23 05:10:30----------------------

Is LLM [prompt engineering](https://en.wikipedia.org/wiki/Prompt_engineering) is the art of asking a questions to the language model, one that is likely to produce a better result. 
The idea looks similar to  ... [Robopsychology](https://en.wikipedia.org/wiki/Robopsychology) in 'I Robot' by Asimov

We are living in an interesting time...

A different view would be, that it's just a way to optimize the results of a search engine.

Now this following [paper](https://arxiv.org/pdf/2212.04037.pdf) argues, that the simplest LLM prompts work best, probably the prompt that has a style and wording nearest to the text of training data has the best chances.

"from the article: "we devise the following straightforward procedure:

1. Obtain a small set of manually created prompts for the task.

2. Expand the set of prompts with automatic paraphrasing using a LM (e.g., GPT3) and backtranslation (see Section 3).

3. Rank the list of prompts by perplexity (aver- aged on a representative sample of task inputs, e.g. 1,000).

4. Choose the k (e.g., 3) lowest perplexity prompts.

Using this algorithm, we show empirically that it is best to prioritize experimenting with the lowest perplexity prompts, as they perform better than manual prompts on average, and are more stable" 


How is the automatic paraphrasing achieved?

* first they paraphrase the hand written prompts: "We prompt it with a meta-prompt for paraphrasing to generate variations of one of our seed prompts. An example of such a meta-prompt is: Write a paraphrase for the following sentence: <seed prompt> Paraphrase:.  The 7 meta-prompts used in this step are listed in Section A in the Appendix.  We choose GPT3 as our paraphrasing model because of its well-documented generation abilities.  This is also to ensure that there is a separation between the model we use to create the prompts and the models we use to rank them (OPT and Bloom, see Section 4 for details)"
* then they translate the text from the previous step to a different language and back into english. (the article doesn't quite explain the reasoning behind this step)


Still there is this interesting practice of 'prompt engineering. https://github.com/brexhq/prompt-engineering#a-brief-incomplete-and-somewhat-incorrect-history-of-language-models



---08/05/23 09:02:53----------------------

Just realized: ChatGTP isn't hallucinating, these are Androids who are dreaming of electric sheep!

Now I am re-reading "Do Androids dream of electric sheep" by Philip K Dick, so writing down the memorable phrases/scenes. [more...](androids-electric-sheep.txt)

/actually pasting out memorable phrases is a nice trick - for staying focused on the text, while you have half a hundred tab windows open in the web browser...
The good part is that this method can help with last point in the text (it's like a bookmark) - just search for the last phrase that got copied in the notes/

... And the Androids in the book also do have hallucinations! "Maybe that's a false memory. Don't androids sometimes go around with false memories?"

---08/05/23 05:56:47----------------------

[Stack Overflow is ChatGPT Casualty: Traffic Down 14% in March](https://www.similarweb.com/blog/insights/ai-news/stack-overflow-chatgpt/)

So where the stack overflow posts ... training their own replacement?
But if any harm comes to SO then the quality of the tech answers in ChatGTP will also be affected.

As Berthold Brecht said "So many reports. So many questions."  [Questions of a reading worker](https://www.emag-augsburg.de/2018/02/21/questions-of-a-reading-worker/)

Submitted the link to HN [discussion on HN](https://news.ycombinator.com/item?id=35857536)

---07/05/23 06:17:15----------------------

I have summed up an interesting interview with Erica Franz on Authoritarian regimes [link to my summary](political-stuff.txt) - with specific reference to Putins attempts to resurrect Stalinism.

In Soviet school they used to teach us that Lenin was writing summaries of the stuff that he read [here](https://prorivists.org/how_lenin_worked_with_a_book/) - so they forced us to do likewise... Somehow i have come to think that this is a good practice (of course Lenin's regime was a very nasty one...)


Interesting that Socrates didn't like to write things down ... among other reasons because it 'destroys memory and weakens the mind'.
[see here](https://blogs.ubc.ca/etec540sept13/2013/09/29/socrates-writing-vs-memory/) 

Interesting that Socrates is reported to have told the story two Egyptian deities Theuth and Thamus. These ancient greeks must have travelled a lot: see [here](https://history.howstuffworks.com/history-vs-myth/greek-philosophers-african-tribes1.htm) 

"It's well-documented that classical Greek thinkers traveled to what we now call Egypt to expand their knowledge. When the Greek scholars Thales, Hippocrates, Pythagoras, Socrates, Plato and others traveled to Kemet, they studied at the temple-universities Waset and Ipet Isut"

---04/05/23 06:34:50----------------------

me talking with ChatGTP on classical AI and the attempts to combine classical AI with ML
[link to the talk](talking-with-chatgtp.md)

I have come to think that ChatGTP is very good at this kind of general discussions.

(also I appreciate the lack of hubris on the part of ChatGTP - very unlike all the real workers in the field. ChatGTP is also always there to explain these frequent acronyms and explains what it is referring to - you just have to ask...)

/later discovered that Google Bard is better at it - because it has a later knowledge cutoff date than ChatGTP3.5 ; this means that the data used to train Google Bard is newer and more up to date than that of ChatGTP3.5/



