
/my opinion: you think go is easy and straigtforward, as it comes from the same guys who wrote C and looks like C. No - it is a very confusing mess../
/i think the mascot of golang should rather be a Pepelatz from the movie Kin-dza-dza - a bit strange, but works (see this awe inspiring talk: https://www.youtube.com/watch?v=-K11rY57K7k&list ) /

--

Standard library reference: https://pkg.go.dev/std
Source for standard library packages: https://github.com/golang/go/tree/master/src

Tutorials:

Tour of go: https://go.dev/tour/welcome/1

Effective go https://go.dev/doc/effective_go

Go playground: https://go.dev/play/

50 Shades of Go: Traps, Gotchas, and Common Mistakes for New Golang Devs http://golang50shad.es/

--

error handling / defer statement. (a bit confusing - if you aske me, in a language with a 'focus on readability'...)
 
- defer statement has a function call: this function call will be called at the end of the function, not the enclosing block (this one is function oriented, not block oriented)
- when defer statement is executed: all argumens to the function (the one that will be called at function exit) are evaluated now!
 the result of these evaluations is stored (behind the scene).
- on function exit: the most recen defer statement is run firs (in last to first order)
- also don't do a defer call in a loop - it will be called in referse order for each iteration...

    package main

    import "fmt"

    func deferedAction(arg int) {

        fmt.Printf("Deferred action. Argument %d\n", arg)
    }

    func prepareDeferedArgument() int {
        fmt.Println("prepareDeferedArgument called")
        return 42
    }

    /* output:

    prepareDeferedArgument called
    code After defer
    Deferred action. Argument 100
    Deferred action. Argument 42
    Deferred action. Argument 1

    */
    func main() {

        defer deferedAction(1)
        defer deferedAction(prepareDeferedArgument())
        defer deferedAction(100)
        fmt.Println("code After defer")
    }


--

- arithmetics: need to cast both operands to the same type (no implicit conversion)

- values:
    There are immutable types:
        numbers, strings

    mutable types:
        slices, maps

- assign with declaration :=

    if left hand side of multiple assign-with-declaration is having one of the variables already declared, then that one is just reassigned (purpose - to simplify code with error object return value)

    func main() {
        one := 0
        //0xc000012028
        fmt.Printf("%v\n", &one)

        //0xc000012028 0xc000012060
        one, two := 1, 2
        fmt.Printf("%v %v\n", &one, &two)
    }

    But: you can't have a struct field access on left hand side of :=  - that is verboten.

    Now this whole := business is a source of shaddowing problems !!!

        func main() {
            one := 0
            fmt.Printf("%v %v\n", one, &one) // 0 0xc000012028
            {
                one := 1
                fmt.Printf("%v %v one got shaddowed when redefined in nested scope! it is a different variable!!!\n", one, &one) // 1 0xc000012058
            }
            fmt.Printf("%v %v\n", one, &one) // 0 0xc000012028
        }


- string values

    A string holds a byte array, this maps one-to-one for english and a few other languages, but if the string contains unicode then things are more much more complex.
    (don't know why they did it this way, maybe they wanted to remain 'low level' or use a byte array read from the network directly as a string - which is not a very good idea for other reasons...)


- functions: parameters are always passed by value.

  Therefore mutable value (such as maps) refer to the same content when passed to a function, so you can modify the content of the map, slice content.

  a map value is just a pointer to an implementation object https://stackoverflow.com/questions/40680981/are-maps-passed-by-value-or-by-reference-in-go source: https://go.dev/src/runtime/map.go )

    package main

    import "fmt"

    func foo(num_map map[string]int) {
        num_map["a"] = 42

        fmt.Printf("in function %p %v %T\n", &num_map, num_map, num_map)
    }

    /*
    in function 0xc00004e028 map[a:42 b:2] map[string]int
    out function 0xc00004e020 map[a:42 b:2] map[string]int
    */
    func main() {

        a := map[string]int{
            "a": 1,
            "b": 2
        }

        foo(a)

        fmt.Printf("out function %p %v %T\n", &a, a, a)
    }

    A slice value is a struct of three values https://go.dev/src/runtime/slice.go
        type slice struct {
            array unsafe.Pointer // pointer to data
            len   int            // length (how many elements have been assigned value in array)  
            cap   int            // capacity (number of elements allocated in array)
        }
    You can change allocated values in the slice, when passing it by value (both copies point to same array)
    But you can't change the size of a slice in a function - that will not be visisble to the caller

        func foo(slc []int) {

            slc[0] = 42

            fmt.Printf("in function %p %v %T\n", &slc, slc, slc)
        }

        /*
        in function 0xc000010030 [42 2 3] []int
        out function 0xc000010018 [42 2 3] []int
         */
        func main() {

            a := make([]int, 3)
            a[0] = 1
            a[1] = 2
            a[2] = 3

            foo(a)

            fmt.Printf("out function %p %v %T\n", &a, a, a)
        }
    

  But beware: the slice value contains the length of the slice, so appending to a slice within a function will not change it (that's why append always returns the updated value - which includes the updated length!!!)


        func foo(slc []int) int {
            slc = append(slc, 420) // always reassign the return value of append !!!

            fmt.Printf("in function %p %v %T\n", &slc, slc, slc)

            return len(slc)
        }

        /*
        in function 0xc000010030 [42 420] []int
        out function 0xc000010018 [42] []int
        */
        func main() {

            a := make([]int, 0)

            a = append(a, 42) // always reassign the return value of append !!!

            foo(a)

            fmt.Printf("out function %p %v %T\n", &a, a, a)
        }

  Now arrays are different: passing an array to the function will copy that array including its data!

        func foo(slc [3]int) {

            slc[0] = 42

            fmt.Printf("in function %p %v %T\n", &slc, slc, slc)
        }

        /*
        in function 0xc000010030 [42 2 3] []int
        out function 0xc000010018 [42 2 3] []int
        */
        func main() {

            a := [3]int{1, 2, 3}

            foo(a)

            fmt.Printf("out function %p %v %T\n", &a, a, a)
        }


----
General question: is data for array allocated on stack or the heap?

They do escape analysis - if they figure that the pointer is not stored in a global variable then it is kept on the stack!!! ( see https://www.youtube.com/watch?v=x87Cs9vU4Fk at 15:25 onwards )

Actually the data values of an array are mostly kept linearly in the allocated array chunk (unlike java, where GC mandates to have another indirection, for every array entry)

----
  pointers: No pointer arithmetics in golang!!!
  But you can work around it with something like this:

    unsafe.Pointer(uintptr(p) + offset) // see https://pkg.go.dev/unsafe
                                        // unsafe.Pointer checks if the argument pointer value is valid...
  
  Also you can access struct fields f in struct value s like this:

    f := unsafe.Pointer(uintptr(unsafe.Pointer(&s)) + unsafe.Offsetof(s.f))

--
maps

    Map internals: "Internals of Maps in Golang" by  Sreekanth -  https://www.youtube.com/watch?v=ACQs6mdylxo
    "GopherCon 2016: Keith Randall - Inside the Map Implementation" -  https://www.youtube.com/watch?v=Tl7mi9QmLns

    - keys can be values that have == operation, and a hash function (you can't set your own comparison or hash on given type - Keith Randall says they don't want denial of service attacks due to hash collisions (adversary safe is the right term), so they do it all themselves, also each hash map instance has a random seeds added to the hahs value, to make the hash function less predictable)

    - comparable types
        - basic types
        - structs where all fields are comparable
        - array is of comparable type - that have an == operation (but slices are not of comparable type - maybe because slice is a view on a array, where the referenced array content can change at any moment)
        - pointers  (they take the pointer value as key, does not dereference the pointer)

            func main() {
                k1 := "a"
                k2 := "b"
                m := map[*string]int{&k1: 3, &k2: 10}
                
                // map[0xc000014070:3 0xc000014080:10] 2
                fmt.Printf("%v %d", m, len(m))
            }

    
    can allocate a map with new (optional param to set size of map - num of elements it can hold before reallocation) -- aka. bucket size.

        m := make(map[string]int, 42) // now you can't use cap to tell you this number - no getter for it.

    or create a map instance - here you can't set the 'size'
        
        m := map[string]int {"a":3,"b":10 } // this way you can set the contnet, but not the 'num of elements before realloc' - 'bucket size'


    
    ====

    map implementation:
        - linear table, divided into buckets (bucket layout - 8 consecutive entries of key, value pairs, and a pointer to an overflow bucket - if there are more than 8 entries in a bucket)
        - growing the map: if a bucket gets to 6.5 entries they decide to grow the table
            - allocate a new bucket, now they don't copy all of the entries from the old bucket to the new bucket at once (big break)
              they copy it incrementally upon each action (what to do with updates, when they have a copy of an entry in both places ?)
        - runtime of map lookup returns pointer to value, but compiler ensures this value is not kept for long (so the vpointer is no longer irrelevant)
    
    
--
structures:

syntax for structure methods that get a pointer to vs copy of self/this object is the same.
Same for usage!


Allocating a new struct and get a pointer to it (memory is garbage collected)

    package main

    import "fmt"

    type Foo struct {
        Name2count map[string]int
    }

    func main() {

        a := new(Foo) // get pointer to allocated Foo - equivalent to &Foo{}, all fields are nil

        // map, slice or channel members need to be created - make can do it 
        // by default the map field is a nill value - using that gives panic.
        //
        a.Name2count = make(map[string]int)
        a.Name2count["la"] = 1

        fmt.Printf("%v %T\n", a, a)

        // returns pointer to allocated Foo struct, allows you to init struct members, can't do that with new
        b := &Foo{Name2count: make(map[string]int)}
        b.Name2count["lala"] = 1

        fmt.Printf("%v %T\n", b, b)
    }

Struct receiver can be both pointer of value, still calling the method is the same for both values and pointers!!!
(for regular function parameters you must explicitly either pass a value or a pointer - unlike receivers)

Reason: when structure is small: copying it is faster than fiddling with pointers! (redirection costs more than copy)

Now: this doesn't apply for regular arguments (other than receiver - argument delcared as pointer must be passed as pointer!)

Example:

    package main

    import  (
        "math"
        "fmt"
    )

    type Point struct {
        X int
        Y int
    }

    //
    // argument structure is small: copying it is faster than fiddling with pointers! (redirection costs more than copy)
    //
    // It's the same syntax for accessing a struct field in a variable that holds a struct value vs accessing a struct field in a reference to a struct. That's a bit confusing for someone who is coming from the land of C.
    //
    func (self Point) Dist(other Point) float64 {
        arg := (other.X - self.X) * (other.X - self.X) + (other.Y - self.Y) * (other.Y - self.Y)
        return math.Sqrt( float64(arg) )
    }

    func (self *Point) Add(other Point) {
        self.X += other.X
        self.Y += other.Y
    }

    // implement the Stringer interface - this way fmt.Println can show the object!
    func (self Point) String() string {
        return fmt.Sprintf("x: %d y: %d", self.X, self.Y)
    }

    func main() {
        p := Point{10, 20}
        other := Point{30, 40}

        fmt.Println("distance between points: ", p.Dist(other))
        p.Add(other)

        fmt.Println("after moving point: ",p)
    }

--

You can append write a string to a null strings.Builder
also null slices can be appended to!!! 

    package main

    import (
        "fmt"
        "strings"
    )

    func main() {

        // golang doesn'thave a char class - for unicode characters it's 'rune'.
        var slc []rune

        for i := 0; i < 10; i++ {
            // you can append something to an empty slice value !!!
            slc = append(slc, rune('b'))
        }
        fmt.Println(string(slc))

        // the values of the fields  for struct strings.Builder are all nil
        // see: https://github.com/golang/go/blob/master/src/strings/builder.go
        //
        var sb strings.Builder

        for i := 0; i < 1000; i++ {
            // method WriteString of strings.Builder can cope with uninitialized fields in its struct.
            // they check if the buffer is nill and init it.
            sb.WriteString("a")
        }
        fmt.Println(sb.String())

    }

but you can't do that with a map variable that is not assigned a map value (happens a lot if a struct member of type map has not been set to a map value!)

    func main() {
        var m map[string]int

        m["this-one-panics"] = 1 // panic here!
    }
    

--
Some objects/structure explicitly deal with nil receivers!!!
(unlike Java you don't get an exception/panic on calling a method with null value for this)


    package main

    import (
        "fmt"
        "math"
    )

    type Circle struct {
        r float64
    }

    func (c *Circle) area() float64 {
        if c == nil {
        // initalize nil receiver
        // (only for this method)
            c = new(Circle)
            c.r = 10
        }
        return math.Pi * c.r * c.r
    }

    func main() {
        var c *Circle
        fmt.Println(c.area()) // returns area

        // will throw panic for c.r, after calling c.area() the object has still nil fields.
        //fmt.Println(c.r)
    }

- interfaces:

Converting a type to a runtime is performed during runtime. Asked google bard about the details, here:  https://g.co/gemini/share/c66468dd3bc0 (Google bard/gemini knows a lot about golang, maybe because both of them come from google ;-) )

Also see this video: "Internals of Interfaces in Golang" by  Sreekanth - https://www.youtube.com/watch?v=x87Cs9vU4Fk


checking for an interface dynamically

    // this guy is built-in in
    type Stringer interface {
        String() string
    }


    // interface{} is empty method set  meaning any interface will match
    // that's how fmt.Printf does it see: https://github.com/golang/go/blob/master/src/fmt/print.go
    //
    func ToString(any interface{}) string {

        // dynamic check at runtime: check if any parameter is supporting the Stringer interface.
        if v, ok := any.(Stringer); ok {
            return v.String()
        }
        // deal with int / float type directly, by switching on the type.
        switch v := any.(type) {
        case int:
            return strconv.Itoa(v)
        case float:
            return strconv.Ftoa(v, 'g', -1)
        }
        return "???"
    }

--
Embedding: all of the members of the embedded struct/interface are copied verbatim into the embedding struct/interface.

That's subclassing in golang!  https://go.dev/doc/effective_go#embedding

For interfaces:

    type Reader interface {
        Read(p []byte) (n int, err error)
    }

    type Writer interface {
        Write(p []byte) (n int, err error)
    }

    // ReadWriter is the interface is the union of Reader and Writer interfaces. (has methods of both interfaces)
    type ReadWriter interface {
        Reader
        Writer
    }

Exmple for struct embedding in bufio packagex:, here:  https://cs.opensource.google/go/go/+/master:src/bufio/bufio.go

// bufio.Reader implements buffering for an io.Reader object.
type Reader struct {
    ...

// bufio.Writer implements buffering for an [io.Writer] object. ... 
type Writer struct {
    ...

// ReadWriter stores pointers to a [bufio.Reader] and a [bufio.Writer].
// It implements [io.ReadWriter].
type ReadWriter struct {
	*Reader
	*Writer
}

// Now the catch: calling the embedded Read method on ReaderWriter receiver will FORWARD THE EMBEDDED *buifIo.Read STRUCTURE TO THE READ METHOD


--

// NewWriterSize returns a new [Writer] whose buffer has at least the specified
// size. If the argument io.Writer is already a [Writer] with large enough
// size, it returns the underlying [Writer].
func NewWriterSize(w io.Writer, size int) *Writer {
....

Go routines 

Channels (for communication between go routines)

Don't write to channel, if no-one is listening. You get panick, when the channel isfull:

    package main

    // writing a channel to full capacity. If no one is listening - panick, deadlock
    func main() {

        /*
        ch := make(chan int)
        ch <- 1  // /*fatal error: all goroutines are asleep - deadlock! */
        */

        ch := make(chan int, 2)
        ch <- 1
        ch <- 2

        ch <- 3
        /*fatal error: all goroutines are asleep - deadlock!

        goroutine 1 [chan send]:
        main.main()
        /home/user/mystuff/my-notes/gostuff/chan1.go:15 +0x56
        */
    }

You can write to a channel capacity + two items

    package main

    import (
        "log"
        "os"
    )

    func makeFib(ch chan int64) {
        logger := log.New(os.Stderr, "", 0)

        n_1 := int64(0)
        n_2 := int64(1)

        idx := 0

        for idx < 20 {
            logger.Println("ch <- :: post: ", idx, n_1)
            ch <- n_1

            num := n_1 + n_2
            n_1 = n_2
            n_2 = num
            idx += 1
        }
        ch <- -1

    }

    /*
    output with capacity == 0 (default)

    Channel capacity: 0
    ch <- :: post:  0 0
    ch <- :: post:  1 1
    <-ch :: received:  0
    <-ch :: received:  1
    ch <- :: post:  2 1
    ch <- :: post:  3 2
    <-ch :: received:  1
    <-ch :: received:  2
    ch <- :: post:  4 3
    ch <- :: post:  5 5
    <-ch :: received:  3
    <-ch :: received:  5
    ch <- :: post:  6 8
    ch <- :: post:  7 13
    <-ch :: received:  8
    <-ch :: received:  13
    ch <- :: post:  8 21
    ch <- :: post:  9 34
    <-ch :: received:  21
    <-ch :: received:  34
    ch <- :: post:  10 55
    ch <- :: post:  11 89
    <-ch :: received:  55
    <-ch :: received:  89
    ch <- :: post:  12 144
    ch <- :: post:  13 233
    <-ch :: received:  144
    <-ch :: received:  233
    ch <- :: post:  14 377
    ch <- :: post:  15 610
    <-ch :: received:  377
    <-ch :: received:  610
    ch <- :: post:  16 987
    ch <- :: post:  17 1597
    <-ch :: received:  987
    <-ch :: received:  1597
    ch <- :: post:  18 2584
    ch <- :: post:  19 4181
    <-ch :: received:  2584
    <-ch :: received:  4181
    <-ch :: received:  -1

    output with capacity == 2 

    Channel capacity: 2
    ch <- :: post:  0 0
    ch <- :: post:  1 1
    ch <- :: post:  2 1
    ch <- :: post:  3 2
    <-ch :: received:  0
    <-ch :: received:  1
    <-ch :: received:  1
    <-ch :: received:  2
    ch <- :: post:  4 3
    ch <- :: post:  5 5
    ch <- :: post:  6 8
    ch <- :: post:  7 13
    <-ch :: received:  3
    <-ch :: received:  5
    <-ch :: received:  8
    <-ch :: received:  13
    ch <- :: post:  8 21
    ch <- :: post:  9 34
    ch <- :: post:  10 55
    ch <- :: post:  11 89
    <-ch :: received:  21
    <-ch :: received:  34
    <-ch :: received:  55
    <-ch :: received:  89
    ch <- :: post:  12 144
    ch <- :: post:  13 233
    ch <- :: post:  14 377
    ch <- :: post:  15 610
    <-ch :: received:  144
    <-ch :: received:  233
    <-ch :: received:  377
    <-ch :: received:  610
    ch <- :: post:  16 987
    ch <- :: post:  17 1597
    ch <- :: post:  18 2584
    ch <- :: post:  19 4181
    <-ch :: received:  987
    <-ch :: received:  1597
    <-ch :: received:  2584
    <-ch :: received:  4181
    <-ch :: received:  -1
    */
    func main() {
        logger := log.New(os.Stderr, "", 0)

        capacity := 0
        logger.Print("Channel capacity: ", capacity)
        ch := make(chan int64, capacity)

        go makeFib(ch)

        var res int64
        for res != -1 {
            res = <-ch
            logger.Println("<-ch :: received: ", res)
        }

    }

----

Go scheduler talk:  

Dmitry Vyukov â€” Go scheduler: Implementing language with lightweight concurrency :: https://www.youtube.com/watch?v=-K11rY57K7k
- requirements:
     - support millions of go routines per process.
     - minimal api (create go routine), no means to specify priority, stack size - runtime has to figure it out.
     - infinite stack size for go routine/  
- How to solve it? go routines - user mode thread (m:n threading n user mode threads running on m OS threads; m < n)
    os threads are expensive
    user mode threads are less expensive,
    Simplified scheduler to organize the user mode threads: (will be refined later)
        - scheduler needs a run queue (scheduled go routines waiting to run), need to synch on it
        - do need to keep track of blocked go-routines? says no: the channel keeps track of go-routines that are blocked on channel with its own wait queue, same for mutexes, timers, network IO.
        - what about blocking on syscalls - these are handled by kernel and go user mode scheduler looses track.
            - lots of potential: real deadlocks, 
            - fake deadlocks: all active OS threads are blocked, waiting for additional thread to wake them up - but all OS threads are all busya`
              Says they fix this way: when an OS threads starts to block on syscall then it wakes up another OS thread (this is called "handoff" - also add another thread one if all threads are exhausted (to prevent fake deadlocks)  later: adjust number of active OS threads, if it grew too large) 

   
   Refining the schedule design:
        - single run queue is bad, too much locking.
            - lock free queue? says no, contention remains (on CPU cache level), as they are looking on the same resource.
            - instead have a run queue per OS thread. (still the global run queue remains - for special cases, it is used less frequently)
            - now we got several run queues, what does an OS thread do when it wants to run the next go routine?
                - first look at per OS thread run queue (local queue)
                - if local run queue is empty: check the global run queue
                - next check network poller for free tasks to run.
                - if nothing in in network poller: works stealing (check run queue of another OS thread and take half of its queued tasks)
                    (this avoids situation where some threads have long queue, others are idle)
               
        - remaining problem:
            - work steeling can be expensive, as lots of local thread queues may need to be checkedd.
            - they have a memalloc cache per CPU, so if a go routine has allocated stuff of that cache then it has to be moved somehow to a new OS thread!
            - Numa problems/CPU local cache problems: sharing memory between CPU's is expensive (due to CPU cache sync)
            
        - says they add another entity to solve this: The Processor object (per CPU core),  
            - the Processor keeps its own per CPU malloc cache (and other caches - didn't say which), 
            - Processor object also keeps the run queue (this means work stealing has fewer queues to check. as the processor is per core (and not per thread)) (what do they do with the cached per CPU allocations upon moving a queue entry upon work stealing, or do they handle that during garbage collection???)
            - so the current thread does a handoff when it is about to do a syscall, this handoff calls another thread and passes the Processor object (work stealing can be done during this handoff!) 

    
    Fairness problem: fairness means that a go routine will _eventually_ run if it is runnable.
        - a single shared run queue is very fair - but it is bad due to lots of locks/contention (last in first out is the opposite of fair)
        - other problems: a thread that is stuck in infinite loop would prevent all the other locally queued go routines to never run (starve)
            - they solve that by preemption of go routine that is running for too long (later they explain how they do that with 
              Now preemted go routines are put to the end of the global run queue (this one is used when the local run queue is exhausted while searching for next task)    
        - the per OS thread local run queue: it is FIFO/queu (not quite: there is one element LIFO/stack buffer at the top of the queue) !!!     . 
            - why? scenario: go routine A creates go routine B and waits for B to finish (to get the return value). This is very common, so they need that FIFO element (also this restricts work stealing for the last element)
                - now problem: go routine A respawns go routine B again and again - everyone else starves/doesn't get scheduled.
                  Solution: time slice inheritance: if go routine A spawns go routine B - B gets the same time slice as A (meaning upon end of time slice it will be preemted - will be put to global run queue)
        - problem: global run queue is checked infrequently? fix: if ++Processor.next_tick_counter % 61 == 0 - then check global run queue instead of local run queue. 
        - problem of network poller starvation (network poller services does epoll on connections with pending network request)
            - occasional invocation of epoll by go scheduler is not enough, so they have additional background thread that does epoll (if not invoked by go scheduler)
            

    
    Infinite stacks for go routines
        - cant' assign large chunk of continious virtual address range for a stack, they want millions of go routines, would run out of virtual space..
        - use split stack instead. Function prologue code needs to check if current linked area will overflow (compiler computes required stack space for function), if yes, then call runtime to allocate the next split stack portion.
        - problem: function prolog can take 2ns (no need to allocate next split stack portion) to 60ns (need to do that). Function call in hot loop can get lots of allocation/deallocation of split stack portion. Same for slight changes in stack space required for a function (impossible to predict that!)
        - solution: also use growable stacks, a stack portion is not fixed size - the size can grow (such a reallocation requires to copy the stack frame to the new location - if the address changed)

    Preemption - sometimes the go scheduler needs to tell the go thread to stop right now.
        - they did not want to force a go-thread to quit with signals because this is OS dependent, and it may kill if you do it during GC or something.
        - instead 'ask nicely' :: still don't want to add any more stuff to function prologue. Now they do a clever trick: set the stack limit to very low, so that to force regular prologue check for segmented stack will call into runtime upon next function call!

    How to improve that beast of a scheduler, what's next?
        - maybe do premtive preemption with signals (still some rough edges here)
        - timers : move them from network poller to processor object
        - scaling to lots of cores
        - NUMA awareness (as of 2019 it was not)

    questions:
        when do they shrink a stack? Part of GC cycle right now
        what about memory fragmentation with variable length stack segments? Says they use allocator with fixed size chunks, so that takes care of it.


Generics
--------
See: Advanced Golang: Generics Explained / Code with Ryan https://www.youtube.com/watch?v=WpTKqnfp5dY


Example:

    package main

    import (
        "fmt"

        // see https://pkg.go.dev/golang.org/x/exp/constraints
        //  
        "golang.org/x/exp/constraints"
    )

    func minn[T constraints.Ordered](x, y T) T {
        if x < y {
            return x
        }
        return y
    }

    func main() {
        fmt.Println("Minimum", minn[int](2, 3))

        // same as...

        fmt.Println("Minimum", minn(2, 3))
    }
        
        
                
                
        




